# GAN for Handwritten Digit Generation
This project implements a Generative Adversarial Network (GAN) to generate handwritten digits similar to those in the MNIST dataset. The MNIST dataset consists of 60,000 training images of handwritten digits and is widely used for training and testing image processing systems.

## Project Overview
The primary objective of this project is to use a GAN model to learn the underlying distribution of the MNIST dataset and generate new images that resemble handwritten digits. The GAN consists of two neural networks: a Generator and a Discriminator.

• The Generator network takes random noise as input and generates digit-like images.

• The Discriminator network attempts to differentiate between real and generated images.

The two networks are trained together in a competitive process, where the generator tries to improve at fooling the discriminator, and the discriminator tries to get better at distinguishing real from fake images.
## Dependencies
To run this project, you need the following libraries:

• 'torch'

• 'torchvision'

• 'matplotlib'

• 'numpy'
You can install the required libraries using pip:



```bash
pip install torch torchvision matplotlib numpy


```
## Dataset
The project uses the MNIST dataset, which contains 28x28 grayscale images of handwritten digits (0-9). The dataset is automatically downloaded and loaded using PyTorch's datasets module.
## How to Run
1. Clone the Repository:
```bash
git clone https://github.com/diaz3z/MNIST-Generation-using-GAN.git

cd MNIST-Generation-using-GAN

```
2. Run the Jupyter Notebook:

3. Open and execute the Jupyter notebook GAN_MNIST.ipynb to train the GAN model and generate new digit images.

3. Training:
The GAN model is trained on the MNIST dataset using a batch size of 16. The training loop alternates between training the generator and discriminator. After training, the generator can create new digit images.

4. Results:
After training, the notebook will display generated digit images. You can also save the generated images for further analysis.

# Visualize Training Progress
Let's visualize the intermediate generator outputs that we saved during the training. This will show us how Generator learns and generates better fake images as training progresses.

Generator output after '1 epoch' of training...
![generated_images_epoch_1](https://github.com/user-attachments/assets/73184f9e-8c0d-4986-9d9f-29ab649fa690)

Generator output after '10 epochs` of training...
![generated_images_epoch_10](https://github.com/user-attachments/assets/4795a852-320a-43c2-a60c-4892bc7ef7dd)

Generator output after '25 epochs` of training...
![generated_images_epoch_50](https://github.com/user-attachments/assets/502417c9-6c66-4442-baaa-a5e290080812)

Generator output after '50 epochs' of training...
![generated_images_epoch_100](https://github.com/user-attachments/assets/8c33ca54-7c45-4a89-aa12-1e802ab95e66)



# Model Architecture
## Generator
The generator is a neural network that takes a random noise vector as input and outputs a 28x28 image. It consists of fully connected layers followed by transposed convolution layers.

## Discriminator
The discriminator is a binary classifier that takes a 28x28 image as input and outputs a probability that the image is real or fake. It consists of convolutional layers followed by fully connected layers.

## Example Output
Here are some sample images generated by the GAN after training:


## License
This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgements
The project is built using PyTorch and Torchvision.
